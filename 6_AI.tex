\section{AI/ML}
\subsection{Local Models}
Run ML models locally with:
\begin{itemize}
    \item \textbf{Ollama} - \url{https://www.ollama.com} - \faLinux/\faApple/\faWindows.\\
    Get up and running with large language models. Run Llama 3.3, DeepSeek-R1, Phi-4, Mistral, Gemma 2, and other models, locally.

\end{itemize}

\subsection{Coding Assistant}
AI coding assistants:
\begin{itemize}
    \item \textbf{GitHub Copilot} - \url{https://github.com/features/copilot}.\\
    By the company OpenAI (i.e. CloseAI), integrates with VSCode and JetBrains IDE.
\end{itemize}
